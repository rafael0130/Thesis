{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01453173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modality A Data Shape: (5, 100, 1)\n",
      "Modality B Data Shape: (5, 100, 1)\n",
      "Modality C Data Shape: (5, 100, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# pip install mne\n",
    "import numpy as np\n",
    "import mne\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt \n",
    "import xml.etree.cElementTree as et\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "\n",
    "# Define example data\n",
    "window_size = 100\n",
    "num_samples = 5\n",
    "channels_A = 1\n",
    "channels_B = 1\n",
    "channels_C = 2\n",
    "\n",
    "# Generate random data for each modality\n",
    "data_A = np.random.randn(num_samples, window_size, channels_A)\n",
    "data_B = np.random.randn(num_samples, window_size, channels_B)\n",
    "data_C = np.random.randn(num_samples, window_size, channels_C)\n",
    "data=[data_A,data_B,data_C]\n",
    "\n",
    "# Printing out the shape of each modality's data\n",
    "print(f\"Modality A Data Shape: {data_A.shape}\")\n",
    "print(f\"Modality B Data Shape: {data_B.shape}\")\n",
    "print(f\"Modality C Data Shape: {data_C.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2caf5236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('00000999-100507_Flow Patient-0.csv')\n",
    "df3 = pd.read_csv('00000999-100507_SpO2.csv')\n",
    "df2 = pd.DataFrame(np.random.randn(20000, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "304c4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, window_size,samp_rate):\n",
    "    windows = []\n",
    "    window_size=window_size*samp_rate\n",
    "    for i in range(0, data.shape[0], window_size):\n",
    "        window = data[i:i+window_size]\n",
    "        if len(window) == window_size:  # Discard incomplete windows (if any)\n",
    "            windows.append(window)\n",
    "    return np.array(windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4bc4609",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch1 = create_dataset(df,30,100)\n",
    "ch2 = create_dataset(df3,30,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe38ef18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496, 3000, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63dc48fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496, 30, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f821cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_modality_encoder(input_shape, modality_name,filters,code_size,l2_rate):\n",
    "    initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
    "    input = tf.keras.layers.Input(input_shape)\n",
    "    x = tf.keras.layers.Conv1D(filters=2 * filters,\n",
    "                               kernel_size=10,\n",
    "                               activation=\"linear\",\n",
    "                               padding=\"same\",\n",
    "                               strides=1,\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(l2_rate),\n",
    "                               kernel_initializer=initializer)(input)\n",
    "\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.PReLU(shared_axes=[1])(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(filters=filters,\n",
    "                               kernel_size=8,\n",
    "                               activation=\"linear\",\n",
    "                               padding=\"same\",\n",
    "                               strides=1,\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(l2_rate),\n",
    "                               kernel_initializer=initializer)(x)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.PReLU(shared_axes=[1])(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(filters=code_size,\n",
    "                               kernel_size=4,\n",
    "                               activation=\"linear\",\n",
    "                               padding=\"same\",\n",
    "                               strides=1,\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(l2_rate),\n",
    "                               kernel_initializer=initializer)(x)\n",
    "    # output = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.PReLU(shared_axes=[1])(x)\n",
    "    output = tf.keras.layers.BatchNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    return tf.keras.models.Model(input, output, name=modality_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "993f29c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\anaconda3\\lib\\site-packages\\keras\\src\\initializers\\initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 3000, 1)]            0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 30, 1)]              0         []                            \n",
      "                                                                                                  \n",
      " flow (Functional)           (None, 3000, 256)            36096     ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " spo2 (Functional)           (None, 30, 256)              36096     ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " global_max_pooling1d (Glob  (None, 256)                  0         ['flow[0][0]']                \n",
      " alMaxPooling1D)                                                                                  \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Gl  (None, 256)                  0         ['spo2[0][0]']                \n",
      " obalMaxPooling1D)                                                                                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256)                  65792     ['global_max_pooling1d[0][0]']\n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 256)                  65792     ['global_max_pooling1d_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 203776 (796.00 KB)\n",
      "Trainable params: 202752 (792.00 KB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# modality specific encoders\n",
    "mod_encoder = []\n",
    "mod_input = []\n",
    "\n",
    "input_shape = (ch1.shape[1], ch1.shape[2])\n",
    "print(input_shape)\n",
    "encoder = get_ts_modality_encoder(input_shape,\n",
    "                                  modality_name='flow',\n",
    "                                  filters=24,\n",
    "                                  code_size=256,\n",
    "                                  l2_rate=1e-4)\n",
    "\n",
    "mod_input.append(tf.keras.layers.Input(shape=input_shape))\n",
    "\n",
    "x_a = encoder(mod_input[-1])\n",
    "x_a = tf.keras.layers.GlobalMaxPooling1D()(x_a)\n",
    "x_a = tf.keras.layers.Dense(256, activation=\"linear\")(x_a)\n",
    "mod_encoder.append(x_a)\n",
    "\n",
    "input_shape = (ch2.shape[1], ch2.shape[2])\n",
    "encoder = get_ts_modality_encoder(input_shape,\n",
    "                                  modality_name='spo2',\n",
    "                                  filters=24,\n",
    "                                  code_size=256,\n",
    "                                  l2_rate=1e-4)\n",
    "\n",
    "mod_input.append(tf.keras.layers.Input(shape=input_shape))\n",
    "\n",
    "x_a = encoder(mod_input[-1])\n",
    "x_a = tf.keras.layers.GlobalMaxPooling1D()(x_a)\n",
    "x_a = tf.keras.layers.Dense(256, activation=\"linear\")(x_a)\n",
    "mod_encoder.append(x_a)\n",
    "# print(mod_input)\n",
    "embedding_model = tf.keras.Model(mod_input, mod_encoder)\n",
    "# input_x=embedding_model.input\n",
    "# print(input_x)\n",
    "# input_x = ([(ch1.shape[1], ch1.shape[2]),(ch2.shape[1], ch2.shape[2])])\n",
    "# xi=embedding_model(input_x)\n",
    "# x = tf.keras.layers.Concatenate()(embedding_model.output)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "# x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "# # Final classification layer\n",
    "# output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# # Define the new model\n",
    "# classifier_model = tf.keras.models.Model(inputs=embedding_model.inputs, outputs=output)\n",
    "# classifier_model.summary()\n",
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c78eb7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family</th>\n",
       "      <th>Type</th>\n",
       "      <th>Start</th>\n",
       "      <th>Duration</th>\n",
       "      <th>end</th>\n",
       "      <th>window_start</th>\n",
       "      <th>window_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Respiratory</td>\n",
       "      <td>ObstructiveApnea</td>\n",
       "      <td>155.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Respiratory</td>\n",
       "      <td>ObstructiveApnea</td>\n",
       "      <td>209.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Respiratory</td>\n",
       "      <td>ObstructiveApnea</td>\n",
       "      <td>264.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>278.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Respiratory</td>\n",
       "      <td>ObstructiveApnea</td>\n",
       "      <td>295.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>308.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Respiratory</td>\n",
       "      <td>ObstructiveApnea</td>\n",
       "      <td>347.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>358.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Respiratory</td>\n",
       "      <td>Hypopnea</td>\n",
       "      <td>14533.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>14545.5</td>\n",
       "      <td>484.0</td>\n",
       "      <td>484.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Respiratory</td>\n",
       "      <td>Hypopnea</td>\n",
       "      <td>14662.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14674.5</td>\n",
       "      <td>488.0</td>\n",
       "      <td>489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Respiratory</td>\n",
       "      <td>ObstructiveApnea</td>\n",
       "      <td>14711.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14721.5</td>\n",
       "      <td>490.0</td>\n",
       "      <td>490.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Respiratory</td>\n",
       "      <td>Hypopnea</td>\n",
       "      <td>14758.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>14770.5</td>\n",
       "      <td>491.0</td>\n",
       "      <td>492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Respiratory</td>\n",
       "      <td>ObstructiveApnea</td>\n",
       "      <td>14794.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>14806.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>493.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Family              Type    Start  Duration      end  window_start  \\\n",
       "0    Respiratory  ObstructiveApnea    155.0      17.0    172.0           5.0   \n",
       "1    Respiratory  ObstructiveApnea    209.0      19.0    228.0           6.0   \n",
       "2    Respiratory  ObstructiveApnea    264.5      14.0    278.5           8.0   \n",
       "3    Respiratory  ObstructiveApnea    295.5      12.5    308.0           9.0   \n",
       "4    Respiratory  ObstructiveApnea    347.0      11.5    358.5          11.0   \n",
       "..           ...               ...      ...       ...      ...           ...   \n",
       "198  Respiratory          Hypopnea  14533.0      12.5  14545.5         484.0   \n",
       "199  Respiratory          Hypopnea  14662.5      12.0  14674.5         488.0   \n",
       "200  Respiratory  ObstructiveApnea  14711.5      10.0  14721.5         490.0   \n",
       "201  Respiratory          Hypopnea  14758.0      12.5  14770.5         491.0   \n",
       "202  Respiratory  ObstructiveApnea  14794.5      11.5  14806.0         493.0   \n",
       "\n",
       "     window_end  \n",
       "0           5.0  \n",
       "1           7.0  \n",
       "2           9.0  \n",
       "3          10.0  \n",
       "4          11.0  \n",
       "..          ...  \n",
       "198       484.0  \n",
       "199       489.0  \n",
       "200       490.0  \n",
       "201       492.0  \n",
       "202       493.0  \n",
       "\n",
       "[203 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations =et.parse(\"00000999-100507.rml\").getroot()\n",
    "events = []\n",
    "samp_rate=100\n",
    "for event in annotations.iter('{http://www.respironics.com/PatientStudy.xsd}Event'):\n",
    "    events.append(event.attrib)\n",
    "events_df= pd.DataFrame(events)\n",
    "events_df.drop(['Machine', 'OriginatedOnDevice'], axis='columns', inplace=True)\n",
    "events_df=events_df[events_df.Family==\"Respiratory\"].reset_index(drop=True)\n",
    "events_df.Start=events_df.Start.astype('float64')\n",
    "events_df.Duration=events_df.Duration.astype('float64')\n",
    "events_df['end']=(events_df.Start+events_df.Duration)\n",
    "events_df['window_start']=events_df.Start//30\n",
    "events_df['window_end']=events_df.end//30\n",
    "events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d50d65ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_set=set(events_df.window_start)|set(events_df.window_end)\n",
    "lbls=[]\n",
    "for i in range(len(ch1)):\n",
    "    if i in events_set:\n",
    "        lbls.append(1)\n",
    "    else:\n",
    "        lbls.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c5451a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls=np.array(lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3882d078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 12s 170ms/step - loss: 10.3376 - accuracy: 0.5200\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 10s 201ms/step - loss: 8.1112 - accuracy: 0.5625\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 10s 209ms/step - loss: 8.2147 - accuracy: 0.5650\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 11s 222ms/step - loss: 7.2252 - accuracy: 0.5725\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 7.0691 - accuracy: 0.5750\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 10s 207ms/step - loss: 6.7369 - accuracy: 0.6400\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 10s 203ms/step - loss: 6.7027 - accuracy: 0.6300\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 10s 203ms/step - loss: 6.8112 - accuracy: 0.6225\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 10s 200ms/step - loss: 6.4559 - accuracy: 0.6550\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 10s 200ms/step - loss: 6.3923 - accuracy: 0.6575\n",
      "3/3 [==============================] - 1s 147ms/step - loss: 6.4168 - accuracy: 0.5208\n",
      "Test accuracy: 0.5208333134651184\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = [ch1[0:400,:,:],ch2[0:400,:,:]],[ch1[400:,:,:],ch2[400:,:,:]],lbls[0:400],lbls[400:]\n",
    "# Step 3: Train Your Model\n",
    "classifier_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "classifier_model.fit(X_train, y_train, epochs=10, batch_size=8)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = classifier_model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b4a56",
   "metadata": {},
   "source": [
    "## Contrastive loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd9bb170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cocoa_loss(ytrue, ypred):\n",
    "    temperature = 0.5\n",
    "    lambd=3.9e-3\n",
    "    scale_loss=1/32\n",
    "    batch_size, dim_size = ypred.shape[1], ypred.shape[0]\n",
    "    print(ypred.shape)\n",
    "    # Positive Pairs\n",
    "    pos_error = []\n",
    "    for i in range(batch_size):\n",
    "        sim = tf.linalg.matmul(ypred[:, i, :], ypred[:, i, :], transpose_b=True)\n",
    "        sim = tf.subtract(tf.ones([dim_size, dim_size], dtype=tf.dtypes.float32), sim)\n",
    "        sim = tf.exp(sim/temperature)\n",
    "        pos_error.append(tf.reduce_mean(sim))\n",
    "    # Negative pairs\n",
    "    neg_error = 0\n",
    "    for i in range(dim_size):\n",
    "        sim = tf.cast(tf.linalg.matmul(ypred[i], ypred[i], transpose_b=True), dtype=tf.dtypes.float32)\n",
    "        sim = tf.exp(sim /temperature)\n",
    "        # sim = tf.add(sim, tf.ones([batch_size, batch_size]))\n",
    "        tri_mask = np.ones(batch_size ** 2, dtype=bool).reshape(batch_size, batch_size)\n",
    "        tri_mask[np.diag_indices(batch_size)] = False\n",
    "        off_diag_sim = tf.reshape(tf.boolean_mask(sim, tri_mask), [batch_size, batch_size - 1])\n",
    "        neg_error += (tf.reduce_mean(off_diag_sim, axis=-1))\n",
    "\n",
    "    error = tf.multiply(tf.reduce_sum(pos_error),scale_loss) + lambd * tf.reduce_sum(neg_error)\n",
    "\n",
    "    return error\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "class DotProduct(tf.keras.layers.Layer):\n",
    "    def call(self, x, y):\n",
    "        x = tf.nn.l2_normalize(x, axis=-1)\n",
    "        y = tf.nn.l2_normalize(y, axis=-1)\n",
    "        return tf.linalg.matmul(x, y, transpose_b=True)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------- #\n",
    "class ContrastiveModel(tf.keras.Model):\n",
    "    def __init__(self, embedding_model, loss_fn, temperature=1.0, **kwargs):\n",
    "        super().__init__()\n",
    "        self.embedding_model = embedding_model\n",
    "        self._temperature = temperature\n",
    "        self._similarity_layer = DotProduct()\n",
    "        self._lossfn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            modality_embeddings = self.embedding_model(data, training=True)\n",
    "\n",
    "            sparse_labels = tf.range(tf.shape(modality_embeddings[0])[0])\n",
    "\n",
    "            pred = modality_embeddings\n",
    "            pred = tf.nn.l2_normalize(tf.stack(pred), axis=-1)\n",
    "\n",
    "            loss = self.compiled_loss(sparse_labels, pred)\n",
    "            loss += sum(self.losses)\n",
    "\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def call(self, input):\n",
    "        return self.embedding_model(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e50fd1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl = ContrastiveModel(embedding_model, cocoa_loss, 1/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7fb6c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 3000, 1)]            0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 30, 1)]              0         []                            \n",
      "                                                                                                  \n",
      " flow (Functional)           (None, 3000, 256)            36096     ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " spo2 (Functional)           (None, 30, 256)              36096     ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " global_max_pooling1d (Glob  (None, 256)                  0         ['flow[0][0]']                \n",
      " alMaxPooling1D)                                                                                  \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Gl  (None, 256)                  0         ['spo2[0][0]']                \n",
      " obalMaxPooling1D)                                                                                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256)                  65792     ['global_max_pooling1d[0][0]']\n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 256)                  65792     ['global_max_pooling1d_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 203776 (796.00 KB)\n",
      "Trainable params: 202752 (792.00 KB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b79c7dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "(2, 8, 256)\n",
      "(2, 8, 256)\n",
      "50/50 [==============================] - 32s 515ms/step - loss: 0.6943\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 26s 528ms/step - loss: 0.6530\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 31s 628ms/step - loss: 0.6522\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 25s 503ms/step - loss: 0.6524\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 28s 552ms/step - loss: 0.6518\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 24s 471ms/step - loss: 0.6508\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 29s 591ms/step - loss: 0.6517\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.6505\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 28s 562ms/step - loss: 0.6512\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 28s 569ms/step - loss: 0.6516\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = [ch1[0:400,:,:],ch2[0:400,:,:]],[ch1[400:,:,:],ch2[400:,:,:]],[lbls[0:400],lbls[0:400]],[lbls[400:],lbls[400:]]\n",
    "# Step 3: Train Your Model\n",
    "\n",
    "ssl.compile(optimizer='adam', loss=cocoa_loss, metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "result = ssl.fit(X_train, epochs=10, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ffdd225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "dot_product\n"
     ]
    }
   ],
   "source": [
    "for layer in ssl.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c179d27",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Layer contrastive_model is not connected, no input to return.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m base_model\u001b[38;5;241m=\u001b[39mssl\n\u001b[1;32m----> 2\u001b[0m base_model\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(\u001b[43mssl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m,ssl\u001b[38;5;241m.\u001b[39moutput)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:2084\u001b[0m, in \u001b[0;36mLayer.input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2071\u001b[0m \u001b[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a layer.\u001b[39;00m\n\u001b[0;32m   2072\u001b[0m \n\u001b[0;32m   2073\u001b[0m \u001b[38;5;124;03mOnly applicable if the layer has exactly one input,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2081\u001b[0m \u001b[38;5;124;03m  AttributeError: If no inbound nodes are found.\u001b[39;00m\n\u001b[0;32m   2082\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2083\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m-> 2084\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   2085\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not connected, no input to return.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2086\u001b[0m     )\n\u001b[0;32m   2087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_node_attribute_at_index(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Layer contrastive_model is not connected, no input to return."
     ]
    }
   ],
   "source": [
    "base_model=ssl\n",
    "base_model=tf.keras.Model(ssl.input,ssl.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73ea378d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Layer contrastive_model is not connected, no input to return.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:2084\u001b[0m, in \u001b[0;36mLayer.input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2071\u001b[0m \u001b[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a layer.\u001b[39;00m\n\u001b[0;32m   2072\u001b[0m \n\u001b[0;32m   2073\u001b[0m \u001b[38;5;124;03mOnly applicable if the layer has exactly one input,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2081\u001b[0m \u001b[38;5;124;03m  AttributeError: If no inbound nodes are found.\u001b[39;00m\n\u001b[0;32m   2082\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2083\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m-> 2084\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   2085\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not connected, no input to return.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2086\u001b[0m     )\n\u001b[0;32m   2087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_node_attribute_at_index(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Layer contrastive_model is not connected, no input to return."
     ]
    }
   ],
   "source": [
    "base_model.input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fdda81",
   "metadata": {},
   "source": [
    "## add the base model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb824977",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Layer contrastive_model_2 is not connected, no input to return.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m base_model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m      3\u001b[0m     layer\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m input_x \u001b[38;5;241m=\u001b[39m \u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\n\u001b[0;32m      5\u001b[0m xi \u001b[38;5;241m=\u001b[39m base_model(input_x)\n\u001b[0;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m Concatenate()(xi)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:2084\u001b[0m, in \u001b[0;36mLayer.input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2071\u001b[0m \u001b[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a layer.\u001b[39;00m\n\u001b[0;32m   2072\u001b[0m \n\u001b[0;32m   2073\u001b[0m \u001b[38;5;124;03mOnly applicable if the layer has exactly one input,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2081\u001b[0m \u001b[38;5;124;03m  AttributeError: If no inbound nodes are found.\u001b[39;00m\n\u001b[0;32m   2082\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2083\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m-> 2084\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   2085\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not connected, no input to return.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2086\u001b[0m     )\n\u001b[0;32m   2087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_node_attribute_at_index(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Layer contrastive_model_2 is not connected, no input to return."
     ]
    }
   ],
   "source": [
    "base_model = ssl\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "input_x = base_model.input\n",
    "xi = base_model(input_x)\n",
    "x = Concatenate()(xi)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(128, activation=\"relu\", kernel_regularizer=l1(self.reg_dense))(x)\n",
    "\n",
    "classifier_model = Dense(\n",
    "    1,\n",
    "    activation=\"sigmoid\",\n",
    "    kernel_regularizer=l1(0.005),\n",
    ")(x)\n",
    "c_model = Model(input_x, classifier_model)\n",
    "c_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"categorical_accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d40f82e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mssl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3403\u001b[0m, in \u001b[0;36mModel.summary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[0;32m   3372\u001b[0m \u001b[38;5;124;03m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[0;32m   3373\u001b[0m \n\u001b[0;32m   3374\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3400\u001b[0m \u001b[38;5;124;03m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[0;32m   3401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m-> 3403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3404\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3405\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3407\u001b[0m     )\n\u001b[0;32m   3408\u001b[0m layer_utils\u001b[38;5;241m.\u001b[39mprint_summary(\n\u001b[0;32m   3409\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3410\u001b[0m     line_length\u001b[38;5;241m=\u001b[39mline_length,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3415\u001b[0m     layer_range\u001b[38;5;241m=\u001b[39mlayer_range,\n\u001b[0;32m   3416\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "ssl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee0c676b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 3000, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape\n",
    "# y_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7283d0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 3000, 1)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create TensorFlow Datasets from your data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(([X_train_modality_1, X_train_modality_2], y_train)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(([X_test_modality_1, X_test_modality_2], y_test)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Compile the model\n",
    "classifier_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "classifier_model.fit(train_dataset, epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = classifier_model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {test_accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
