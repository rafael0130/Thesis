{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01453173",
        "outputId": "919927b0-e906-43e6-d497-ae7177d3a761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# pip install mne\n",
        "# import mne\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.cElementTree as et\n",
        "import tensorflow as tf\n",
        "import librosa\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import time\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "rootpath='/content/drive/MyDrive/thesis/'"
      ],
      "id": "01453173"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "304c4fbd"
      },
      "outputs": [],
      "source": [
        "def create_dataset(data, window_size,samp_rate):\n",
        "    windows = []\n",
        "    window_size=window_size*samp_rate\n",
        "    for i in range(0, data.shape[0], window_size):\n",
        "        window = data[i:i+window_size]\n",
        "        if len(window) == window_size:  # Discard incomplete windows (if any)\n",
        "            windows.append(window)\n",
        "    return np.array(windows)\n",
        "\n",
        "def create_mfccs(data):\n",
        "    data=data.reshape(data.shape[0],)\n",
        "    mfccs = librosa.feature.mfcc(y=data,n_mfcc =13,sr=500)\n",
        "    delta = librosa.feature.delta(mfccs)\n",
        "    delta2 = librosa.feature.delta(mfccs,order=2)\n",
        "    mfccs_concat = np.concatenate((mfccs,delta,delta2))\n",
        "    return mfccs_concat\n",
        "def get_labels(rootpath,patient_num,event_type,window_size,ch_len):\n",
        "  annotations =et.parse(rootpath+\"0000\"+patient_num+\"-100507.rml\").getroot()\n",
        "  events = []\n",
        "  # samp_rate=100\n",
        "  for event in annotations.iter('{http://www.respironics.com/PatientStudy.xsd}Event'):\n",
        "      events.append(event.attrib)\n",
        "  events_df= pd.DataFrame(events)\n",
        "  events_df.drop(['Machine', 'OriginatedOnDevice'], axis='columns', inplace=True)\n",
        "  events_df=events_df[events_df.Family==event_type].reset_index(drop=True)\n",
        "  events_df.Start=events_df.Start.astype('float64')\n",
        "  events_df.Duration=events_df.Duration.astype('float64')\n",
        "  events_df['end']=(events_df.Start+events_df.Duration)\n",
        "  events_df['window_start']=events_df.Start//window_size\n",
        "  events_df['window_end']=events_df.end//window_size\n",
        "  # print(events_df)\n",
        "  events_set=set(events_df.window_start)|set(events_df.window_end)\n",
        "  lbls=[]\n",
        "  for i in range(ch_len):\n",
        "      if i in events_set:\n",
        "          lbls.append(1)\n",
        "      else:\n",
        "          lbls.append(0)\n",
        "  return lbls\n",
        "\n",
        "\n",
        "def load_data(pre_train_list,downstream_list,window_size,ch4=False):\n",
        "  first=True\n",
        "  for num in pre_train_list:\n",
        "    df = pd.read_csv(rootpath+'0000'+num+'-100507_Flow Patient-0.csv')\n",
        "    df2 = pd.read_csv(rootpath+'0000'+num+'-100507_SpO2.csv')\n",
        "    df3 = pd.read_csv(rootpath+'0000'+num+'-100507_Snore.csv')\n",
        "    # df4 = pd.read_csv(rootpath+'0000'+num+'-100507_ECG I.csv')\n",
        "    ch1_temp = create_dataset(df,window_size,100)\n",
        "    ch2_temp = create_dataset(df2,window_size,1)\n",
        "    ch3_temp = create_dataset(df3,window_size,500)\n",
        "    # ch4_temp = create_dataset(df3,window_size,200)\n",
        "    ch_len=len(ch1_temp)\n",
        "    lbls1_temp = get_labels(rootpath,num,\"Neuro\",window_size,ch_len)\n",
        "    lbls2_temp = get_labels(rootpath,num,\"SpO2\",window_size,ch_len)\n",
        "    lbls3_temp = get_labels(rootpath,num,\"Nasal\",window_size,ch_len)\n",
        "    lbls_temp = get_labels(rootpath,num,\"Respiratory\",window_size,ch_len)\n",
        "    if first:\n",
        "      ch1=ch1_temp\n",
        "      ch2=ch2_temp\n",
        "      ch3=ch3_temp\n",
        "      lbls1=lbls1_temp\n",
        "      lbls2=lbls2_temp\n",
        "      lbls3=lbls3_temp\n",
        "      lbls=lbls_temp\n",
        "      first=False\n",
        "    else:\n",
        "      ch1=np.concatenate((ch1,ch1_temp))\n",
        "      ch2=np.concatenate((ch2,ch2_temp))\n",
        "      ch3=np.concatenate((ch3,ch3_temp))\n",
        "      lbls1=np.concatenate((lbls1,lbls1_temp))\n",
        "      lbls2=np.concatenate((lbls2,lbls2_temp))\n",
        "      lbls3=np.concatenate((lbls3,lbls3_temp))\n",
        "      lbls=np.concatenate((lbls,lbls_temp))\n",
        "\n",
        "  ch3_mod = []\n",
        "  for item in range(len(ch3)):\n",
        "      result = create_mfccs(ch3[item]).reshape(39,30,1)\n",
        "      ch3_mod.append(result)\n",
        "  ch3_mod=np.array(ch3_mod)\n",
        "\n",
        "  #DOWNSTREAM\n",
        "  first=True\n",
        "  window_size=30\n",
        "  for num in downstream_list:\n",
        "    df = pd.read_csv(rootpath+'0000'+num+'-100507_Flow Patient-0.csv')\n",
        "    df2 = pd.read_csv(rootpath+'0000'+num+'-100507_SpO2.csv')\n",
        "    df3 = pd.read_csv(rootpath+'0000'+num+'-100507_Snore.csv')\n",
        "    ch1_temp = create_dataset(df,window_size,100)\n",
        "    ch2_temp = create_dataset(df2,window_size,1)\n",
        "    ch3_temp = create_dataset(df3,window_size,500)\n",
        "    ch_len=len(ch1_temp)\n",
        "    lbls_temp = get_labels(rootpath,num,\"Respiratory\",window_size,ch_len)\n",
        "    if first:\n",
        "      ch1_down=ch1_temp\n",
        "      ch2_down=ch2_temp\n",
        "      ch3_down=ch3_temp\n",
        "      lbls_down=lbls_temp\n",
        "      first=False\n",
        "    else:\n",
        "      ch1_down=np.concatenate((ch1_down,ch1_temp))\n",
        "      ch2_down=np.concatenate((ch2_down,ch2_temp))\n",
        "      ch3_down=np.concatenate((ch3_down,ch3_temp))\n",
        "      lbls_down=np.concatenate((lbls_down,lbls_temp))\n",
        "\n",
        "  ch3_down_mod = []\n",
        "  for item in range(len(ch3_down)):\n",
        "      result = create_mfccs(ch3_down[item]).reshape(39,30,1)\n",
        "      ch3_down_mod.append(result)\n",
        "  ch3_down_mod=np.array(ch3_down_mod)\n",
        "\n",
        "  balance = {}\n",
        "  balance[\"flow\"]=sum(lbls1)/ch1.shape[0]\n",
        "  balance[\"spo2\"]=sum(lbls2)/ch2.shape[0]\n",
        "  balance[\"noise\"]=sum(lbls3)/ch3.shape[0]\n",
        "  balance[\"apnea\"]=sum(lbls_down)/lbls_down.shape[0]\n",
        "\n",
        "  idx = np.random.randint(lbls.shape[0], size=lbls.shape[0])\n",
        "  idx2 = np.random.randint(lbls_down.shape[0], size=lbls_down.shape[0])\n",
        "\n",
        "  ch1=ch1[idx]\n",
        "  ch2=ch2[idx]\n",
        "  ch3_mod=ch3_mod[idx]\n",
        "  lbls1=lbls1[idx]\n",
        "  lbls2=lbls2[idx]\n",
        "  lbls3=lbls3[idx]\n",
        "  lbls=lbls[idx]\n",
        "\n",
        "  ch1_down=ch1_down[idx2]\n",
        "  ch2_down=ch2_down[idx2]\n",
        "  ch3_down_mod=ch3_down_mod[idx2]\n",
        "  lbls_down=lbls_down[idx2]\n",
        "\n",
        "  split_ratio = int(lbls.shape[0] * 0.8)\n",
        "  split_ratio_down = int(lbls_down.shape[0] * 0.8)\n",
        "\n",
        "  return ch1,ch2,ch3_mod,lbls1,lbls2,lbls3,lbls,ch1_down,ch2_down,ch3_down_mod,lbls_down,split_ratio,split_ratio_down,balance"
      ],
      "id": "304c4fbd"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "2GBzdI5aBlkq",
        "outputId": "f1fdfbfc-8b05-4aaa-83fb-d6119d7df1be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  Start  Duration\n",
              "Family      Type                                 \n",
              "Cardiac     LongRR                  905       905\n",
              "            Tachycardia             170       170\n",
              "Limb        LegMovement            1620      1620\n",
              "Nasal       Snore                    65        65\n",
              "Neuro       Arousal                1425      1425\n",
              "Respiratory CentralApnea             60        60\n",
              "            Hypopnea                240       240\n",
              "            MixedApnea              100       100\n",
              "            ObstructiveApnea        615       615\n",
              "SpO2        RelativeDesaturation    345       345\n",
              "User        ChannelFail             515       515\n",
              "            Gain                    295       295"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f194fc71-4290-4e09-aa60-d25fab6af2d1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Start</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Family</th>\n",
              "      <th>Type</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Cardiac</th>\n",
              "      <th>LongRR</th>\n",
              "      <td>905</td>\n",
              "      <td>905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tachycardia</th>\n",
              "      <td>170</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Limb</th>\n",
              "      <th>LegMovement</th>\n",
              "      <td>1620</td>\n",
              "      <td>1620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nasal</th>\n",
              "      <th>Snore</th>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neuro</th>\n",
              "      <th>Arousal</th>\n",
              "      <td>1425</td>\n",
              "      <td>1425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">Respiratory</th>\n",
              "      <th>CentralApnea</th>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hypopnea</th>\n",
              "      <td>240</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MixedApnea</th>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ObstructiveApnea</th>\n",
              "      <td>615</td>\n",
              "      <td>615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SpO2</th>\n",
              "      <th>RelativeDesaturation</th>\n",
              "      <td>345</td>\n",
              "      <td>345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">User</th>\n",
              "      <th>ChannelFail</th>\n",
              "      <td>515</td>\n",
              "      <td>515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gain</th>\n",
              "      <td>295</td>\n",
              "      <td>295</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f194fc71-4290-4e09-aa60-d25fab6af2d1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f194fc71-4290-4e09-aa60-d25fab6af2d1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f194fc71-4290-4e09-aa60-d25fab6af2d1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a5d77d82-8445-4157-8591-0b52222957d9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a5d77d82-8445-4157-8591-0b52222957d9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a5d77d82-8445-4157-8591-0b52222957d9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f97c3f11-aab5-4c8d-9a0a-f9826ddd74c1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('events_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f97c3f11-aab5-4c8d-9a0a-f9826ddd74c1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('events_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "events = []\n",
        "for num in [\"1122\",\"1127\",\"1129\",\"1131\",\"1135\"]:\n",
        "  annotations =et.parse(rootpath+\"00000999-100507.rml\").getroot()\n",
        "  for event in annotations.iter('{http://www.respironics.com/PatientStudy.xsd}Event'):\n",
        "      events.append(event.attrib)\n",
        "events_df= pd.DataFrame(events)\n",
        "events_df.drop(['Machine', 'OriginatedOnDevice'], axis='columns', inplace=True)\n",
        "events_df=events_df.groupby(['Family','Type']).agg('count')\n",
        "events_df"
      ],
      "id": "2GBzdI5aBlkq"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KxhNB_sdM-zf"
      },
      "outputs": [],
      "source": [
        "# first=True\n",
        "# window_size=30\n",
        "# # for num in [\"0995\",\"0999\",\"1000\",\"1006\",\"1008\",\"1010\",\"1014\",\"1016\",\"1018\",\"1020\"]:\n",
        "# for num in [\"0995\",\"0999\",\"1000\",\"1006\",\"1008\",\"1010\",\"1014\",\"1016\",\"1018\",\"1020\",\\\n",
        "#             \"1022\",\"1024\",\"1026\",\"1028\",\"1037\",\"1039\",\"1041\",\"1043\",\"1045\",\"1057\",\\\n",
        "#             \"1059\",\"1069\",\"1071\",\"1073\",\"1082\",\"1084\",\"1086\",\"1088\",\"1089\",\"1093\",\\\n",
        "#             \"1122\",\"1127\",\"1129\",\"1131\",\"1135\",\"1137\",\"1139\",\"1143\",\"1145\",\"1147\"]:\n",
        "#             # \"1095\",\"1097\",\"1104\",\"1106\",\"1108\",\"1110\",\"1112\",\"1116\",\"1118\",\"1120\"]:\n",
        "#   df = pd.read_csv(rootpath+'0000'+num+'-100507_Flow Patient-0.csv')\n",
        "#   df2 = pd.read_csv(rootpath+'0000'+num+'-100507_SpO2.csv')\n",
        "#   df3 = pd.read_csv(rootpath+'0000'+num+'-100507_Snore.csv')\n",
        "#   ch1_temp = create_dataset(df,window_size,100)\n",
        "#   ch2_temp = create_dataset(df2,window_size,1)\n",
        "#   ch3_temp = create_dataset(df3,window_size,500)\n",
        "#   ch_len=len(ch1_temp)\n",
        "#   lbls1_temp = get_labels(rootpath,num,\"Neuro\",window_size,ch_len)\n",
        "#   lbls2_temp = get_labels(rootpath,num,\"SpO2\",window_size,ch_len)\n",
        "#   lbls3_temp = get_labels(rootpath,num,\"Nasal\",window_size,ch_len)\n",
        "#   lbls_temp = get_labels(rootpath,num,\"Respiratory\",window_size,ch_len)\n",
        "#   if first:\n",
        "#     ch1=ch1_temp\n",
        "#     ch2=ch2_temp\n",
        "#     ch3=ch3_temp\n",
        "#     lbls1=lbls1_temp\n",
        "#     lbls2=lbls2_temp\n",
        "#     lbls3=lbls3_temp\n",
        "#     lbls=lbls_temp\n",
        "#     first=False\n",
        "#   else:\n",
        "#     ch1=np.concatenate((ch1,ch1_temp))\n",
        "#     ch2=np.concatenate((ch2,ch2_temp))\n",
        "#     ch3=np.concatenate((ch3,ch3_temp))\n",
        "#     lbls1=np.concatenate((lbls1,lbls1_temp))\n",
        "#     lbls2=np.concatenate((lbls2,lbls2_temp))\n",
        "#     lbls3=np.concatenate((lbls3,lbls3_temp))\n",
        "#     lbls=np.concatenate((lbls,lbls_temp))\n",
        "\n",
        "# ch3_mod = []\n",
        "# for item in range(len(ch3)):\n",
        "#     result = create_mfccs(ch3[item]).reshape(39,30,1)\n",
        "#     ch3_mod.append(result)\n",
        "# #     plt.figure(figsize=(25,10))\n",
        "# #     librosa.display.specshow(result,x_axis='time',sr=500)\n",
        "# #     plt.colorbar(format='%+2f')\n",
        "# ch3_mod=np.array(ch3_mod)\n",
        "\n"
      ],
      "id": "KxhNB_sdM-zf"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AgHNU2nu_nEe"
      },
      "outputs": [],
      "source": [
        "# first=True\n",
        "# window_size=30\n",
        "# # for num in [\"1122\",\"1127\",\"1129\",\"1131\",\"1135\",\"1137\",\"1139\",\"1143\",\"1145\",\"1147\"]:\n",
        "# for num in [\"1095\",\"1097\",\"1104\",\"1106\",\"1108\",\"1110\",\"1112\",\"1116\",\"1118\",\"1120\"]:\n",
        "# # for num in [\"1122\",\"1127\",\"1129\",\"1131\",\"1135\"]:\n",
        "#   df = pd.read_csv(rootpath+'0000'+num+'-100507_Flow Patient-0.csv')\n",
        "#   df2 = pd.read_csv(rootpath+'0000'+num+'-100507_SpO2.csv')\n",
        "#   df3 = pd.read_csv(rootpath+'0000'+num+'-100507_Snore.csv')\n",
        "#   ch1_temp = create_dataset(df,window_size,100)\n",
        "#   ch2_temp = create_dataset(df2,window_size,1)\n",
        "#   ch3_temp = create_dataset(df3,window_size,500)\n",
        "#   ch_len=len(ch1_temp)\n",
        "#   lbls_temp = get_labels(rootpath,num,\"Respiratory\",window_size,ch_len)\n",
        "#   if first:\n",
        "#     ch1_down=ch1_temp\n",
        "#     ch2_down=ch2_temp\n",
        "#     ch3_down=ch3_temp\n",
        "#     lbls_down=lbls_temp\n",
        "#     first=False\n",
        "#   else:\n",
        "#     ch1_down=np.concatenate((ch1_down,ch1_temp))\n",
        "#     ch2_down=np.concatenate((ch2_down,ch2_temp))\n",
        "#     ch3_down=np.concatenate((ch3_down,ch3_temp))\n",
        "#     lbls_down=np.concatenate((lbls_down,lbls_temp))\n",
        "\n",
        "# ch3_down_mod = []\n",
        "# for item in range(len(ch3_down)):\n",
        "#     result = create_mfccs(ch3_down[item]).reshape(39,30,1)\n",
        "#     ch3_down_mod.append(result)\n",
        "# #     plt.figure(figsize=(25,10))\n",
        "# #     librosa.display.specshow(result,x_axis='time',sr=500)\n",
        "# #     plt.colorbar(format='%+2f')\n",
        "# ch3_down_mod=np.array(ch3_down_mod)"
      ],
      "id": "AgHNU2nu_nEe"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fe38ef18"
      },
      "outputs": [],
      "source": [
        "# print(ch1.shape,ch2.shape,ch3_mod.shape,lbls.shape)\n",
        "# print(lbls_down.shape)"
      ],
      "id": "fe38ef18"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CkLsA_uIPpXI"
      },
      "outputs": [],
      "source": [
        "# print(sum(lbls1),sum(lbls2),sum(lbls3),sum(lbls))\n",
        "# print(sum(lbls_down))"
      ],
      "id": "CkLsA_uIPpXI"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g1iiXQO_UL6A"
      },
      "outputs": [],
      "source": [
        "# idx = np.random.randint(lbls.shape[0], size=lbls.shape[0])\n",
        "# idx2 = np.random.randint(lbls_down.shape[0], size=lbls_down.shape[0])"
      ],
      "id": "g1iiXQO_UL6A"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fPgOb5ixUPth"
      },
      "outputs": [],
      "source": [
        "# ch1=ch1[idx]\n",
        "# ch2=ch2[idx]\n",
        "# ch3_mod=ch3_mod[idx]\n",
        "# lbls1=lbls1[idx]\n",
        "# lbls2=lbls2[idx]\n",
        "# lbls3=lbls3[idx]\n",
        "# lbls=lbls[idx]\n",
        "\n",
        "# ch1_down=ch1_down[idx2]\n",
        "# ch2_down=ch2_down[idx2]\n",
        "# ch3_down_mod=ch3_down_mod[idx2]\n",
        "# lbls_down=lbls_down[idx2]"
      ],
      "id": "fPgOb5ixUPth"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "58-JuBrDU6Yj"
      },
      "outputs": [],
      "source": [
        "# split_ratio = int(lbls.shape[0] * 0.8)\n",
        "# split_ratio_down = int(lbls_down.shape[0] * 0.8)"
      ],
      "id": "58-JuBrDU6Yj"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f821cbfe"
      },
      "outputs": [],
      "source": [
        "def encoder_1d(input_shape, modality_name,filters,code_size,l2_rate):\n",
        "    initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
        "    input = tf.keras.layers.Input(input_shape)\n",
        "    x = tf.keras.layers.Conv1D(filters=2 * filters,\n",
        "                               kernel_size=10,\n",
        "                               activation=\"linear\",\n",
        "                               padding=\"same\",\n",
        "                               strides=1,\n",
        "                               kernel_regularizer=tf.keras.regularizers.l2(l2_rate),\n",
        "                               kernel_initializer=initializer)(input)\n",
        "\n",
        "    x = tf.keras.layers.LayerNormalization()(x)\n",
        "    x = tf.keras.layers.PReLU(shared_axes=[1])(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv1D(filters=filters,\n",
        "                               kernel_size=8,\n",
        "                               activation=\"linear\",\n",
        "                               padding=\"same\",\n",
        "                               strides=1,\n",
        "                               kernel_regularizer=tf.keras.regularizers.l2(l2_rate),\n",
        "                               kernel_initializer=initializer)(x)\n",
        "    x = tf.keras.layers.LayerNormalization()(x)\n",
        "    x = tf.keras.layers.PReLU(shared_axes=[1])(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv1D(filters=code_size,\n",
        "                               kernel_size=4,\n",
        "                               activation=\"linear\",\n",
        "                               padding=\"same\",\n",
        "                               strides=1,\n",
        "                               kernel_regularizer=tf.keras.regularizers.l2(l2_rate),\n",
        "                               kernel_initializer=initializer)(x)\n",
        "    # output = tf.keras.layers.LayerNormalization()(x)\n",
        "    x = tf.keras.layers.PReLU(shared_axes=[1])(x)\n",
        "    output = tf.keras.layers.BatchNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    return tf.keras.models.Model(input, output, name=modality_name)\n",
        "\n",
        "def encoder_2d(input_shape, modality_name,filters):\n",
        "    input = tf.keras.layers.Input(input_shape) #input_shape=(height, width, channels)\n",
        "    # Add a 2D convolutional layer with 32 filters, 5x5 kernel size, and 'relu' activation\n",
        "    x = tf.keras.layers.Conv2D(filters, (5, 5), activation='relu')(input)\n",
        "\n",
        "    # Add a 2D max pooling layer with 2x2 pool size\n",
        "    x=tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Add a dropout layer with a dropout rate of 0.25 (adjust as needed)\n",
        "    x=tf.keras.layers.Dropout(0.25)(x)\n",
        "\n",
        "    # Add a 2D convolutional layer with 32 filters, 5x5 kernel size, and 'relu' activation\n",
        "    x = tf.keras.layers.Conv2D(filters*2, (4, 4), activation='relu')(x)\n",
        "\n",
        "    # Add a 2D max pooling layer with 2x2 pool size\n",
        "    x=tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Add a dropout layer with a dropout rate of 0.25 (adjust as needed)\n",
        "    x=tf.keras.layers.Dropout(0.25)(x)\n",
        "\n",
        "    # Add a 2D convolutional layer with 32 filters, 5x5 kernel size, and 'relu' activation\n",
        "    x = tf.keras.layers.Conv2D(filters*3, (3, 3), activation='relu')(x)\n",
        "\n",
        "    # Add a dropout layer with a dropout rate of 0.25 (adjust as needed)\n",
        "    output=tf.keras.layers.Dropout(0.25)(x)\n",
        "\n",
        "    return tf.keras.models.Model(input, output, name=modality_name)"
      ],
      "id": "f821cbfe"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "993f29c3",
        "outputId": "88063dc2-919c-44f8-e4b5-44cf813ab11f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 3000, 1)]            0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 30, 1)]              0         []                            \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)        [(None, 39, 30, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " flow (Functional)           (None, 3000, 256)            36096     ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " spo2 (Functional)           (None, 30, 256)              36096     ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " snore (Functional)          (None, 5, 3, 108)            112572    ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " global_max_pooling1d (Glob  (None, 256)                  0         ['flow[0][0]']                \n",
            " alMaxPooling1D)                                                                                  \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Gl  (None, 256)                  0         ['spo2[0][0]']                \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " global_max_pooling2d (Glob  (None, 108)                  0         ['snore[0][0]']               \n",
            " alMaxPooling2D)                                                                                  \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256)                  65792     ['global_max_pooling1d[0][0]']\n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 256)                  65792     ['global_max_pooling1d_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 256)                  27904     ['global_max_pooling2d[0][0]']\n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 344252 (1.31 MB)\n",
            "Trainable params: 343228 (1.31 MB)\n",
            "Non-trainable params: 1024 (4.00 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 3000, 1)]            0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 30, 1)]              0         []                            \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)        [(None, 39, 30, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " flow (Functional)           (None, 3000, 256)            36096     ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " spo2 (Functional)           (None, 30, 256)              36096     ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " snore (Functional)          (None, 5, 3, 108)            112572    ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " global_max_pooling1d (Glob  (None, 256)                  0         ['flow[0][0]']                \n",
            " alMaxPooling1D)                                                                                  \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Gl  (None, 256)                  0         ['spo2[0][0]']                \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " global_max_pooling2d (Glob  (None, 108)                  0         ['snore[0][0]']               \n",
            " alMaxPooling2D)                                                                                  \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256)                  65792     ['global_max_pooling1d[0][0]']\n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 256)                  65792     ['global_max_pooling1d_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 256)                  27904     ['global_max_pooling2d[0][0]']\n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 128)                  32896     ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 128)                  32896     ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 128)                  32896     ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 1)                    129       ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 1)                    129       ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 1)                    129       ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 443327 (1.69 MB)\n",
            "Trainable params: 442303 (1.69 MB)\n",
            "Non-trainable params: 1024 (4.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# modality specific encoders\n",
        "ch1,ch2,ch3_mod,lbls1,lbls2,lbls3,lbls,ch1_down,ch2_down,ch3_down_mod,lbls_down,split_ratio,split_ratio_down,balance=load_data(['0995',\"0999\"],['0995',\"0999\"],30)\n",
        "mod_encoder = []\n",
        "mod_preclass= []\n",
        "mod_input = []\n",
        "\n",
        "input_shape = (ch1.shape[1], ch1.shape[2])\n",
        "encoder = encoder_1d(input_shape,\n",
        "                                  modality_name='flow',\n",
        "                                  filters=24,\n",
        "                                  code_size=256,\n",
        "                                  l2_rate=1e-4)\n",
        "\n",
        "\n",
        "mod_input.append(tf.keras.layers.Input(shape=input_shape))\n",
        "\n",
        "x_a = encoder(mod_input[-1])\n",
        "x_a = tf.keras.layers.GlobalMaxPooling1D()(x_a)\n",
        "x_a = tf.keras.layers.Dense(256, activation=\"linear\")(x_a)\n",
        "mod_encoder.append(x_a)\n",
        "x_a = tf.keras.layers.Dense(128, activation=\"relu\")(x_a)\n",
        "x_a = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x_a)\n",
        "mod_preclass.append(x_a)\n",
        "\n",
        "input_shape = (ch2.shape[1], ch2.shape[2])\n",
        "encoder = encoder_1d(input_shape,\n",
        "                                  modality_name='spo2',\n",
        "                                  filters=24,\n",
        "                                  code_size=256,\n",
        "                                  l2_rate=1e-4)\n",
        "\n",
        "mod_input.append(tf.keras.layers.Input(shape=input_shape))\n",
        "\n",
        "x_a = encoder(mod_input[-1])\n",
        "x_a = tf.keras.layers.GlobalMaxPooling1D()(x_a)\n",
        "x_a = tf.keras.layers.Dense(256, activation=\"linear\")(x_a)\n",
        "mod_encoder.append(x_a)\n",
        "x_a = tf.keras.layers.Dense(128, activation=\"relu\")(x_a)\n",
        "x_a = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x_a)\n",
        "mod_preclass.append(x_a)\n",
        "\n",
        "\n",
        "input_shape = (ch3_mod.shape[1], ch3_mod.shape[2],ch3_mod.shape[3])\n",
        "encoder = encoder_2d(input_shape,\n",
        "                                  modality_name='snore',\n",
        "                                  filters=36)\n",
        "\n",
        "mod_input.append(tf.keras.layers.Input(shape=input_shape))\n",
        "\n",
        "x_a = encoder(mod_input[-1])\n",
        "x_a = tf.keras.layers.GlobalMaxPooling2D()(x_a)\n",
        "x_a = tf.keras.layers.Dense(256, activation=\"linear\")(x_a)\n",
        "mod_encoder.append(x_a)\n",
        "x_a = tf.keras.layers.Dense(128, activation=\"relu\")(x_a)\n",
        "x_a = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x_a)\n",
        "mod_preclass.append(x_a)\n",
        "\n",
        "\n",
        "embedding_model = tf.keras.Model(mod_input, mod_encoder)\n",
        "preclass_model = tf.keras.Model(mod_input, mod_preclass)\n",
        "\n",
        "embedding_model.summary()\n",
        "preclass_model.summary()"
      ],
      "id": "993f29c3"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hyk4ubPDAD7E"
      },
      "outputs": [],
      "source": [
        "earlyStopping_class = EarlyStopping(monitor=\"loss\",min_delta=0.00009,patience=6,verbose=2,mode=\"auto\",restore_best_weights=True)\n",
        "\n",
        "earlyStopping_ssl = EarlyStopping(monitor=\"loss\",\n",
        "                                      min_delta=0.00009,\n",
        "                                      patience=5,\n",
        "                                      verbose=1,\n",
        "                                      mode=\"min\",\n",
        "                                      restore_best_weights=True\n",
        "                                      )\n",
        "\n",
        "\n",
        "# from keras.callbacks import Callback\n",
        "\n",
        "# class CustomCallback(Callback):\n",
        "#     def on_epoch_end(self, epoch, logs=None):\n",
        "#         if epoch % 10 == 0:  # Check if it's the 10th epoch\n",
        "#             loss, acc = self.model.evaluate(x_val, y_val, verbose=0)\n",
        "#             print(f'\\nEvaluation loss and accuracy after epoch {epoch}: {loss:.4f}, {acc:.4f}\\n')"
      ],
      "id": "hyk4ubPDAD7E"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiDPC8XBFklm"
      },
      "source": [
        "## PRE-Classification method"
      ],
      "id": "GiDPC8XBFklm"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "j1EpmuC6FdvC"
      },
      "outputs": [],
      "source": [
        "preclass_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=[\"binary_crossentropy\",\"binary_crossentropy\",\"binary_crossentropy\"],\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()],\n",
        ")\n"
      ],
      "id": "j1EpmuC6FdvC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "486b4a56"
      },
      "source": [
        "## Contrastive loss"
      ],
      "id": "486b4a56"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cd9bb170"
      },
      "outputs": [],
      "source": [
        "class customLoss:\n",
        "  def __init__(self,temperature=0.5,lambd = 3.9e-3,scale_loss= 1/32):\n",
        "    self.temperature = temperature\n",
        "    self.lambd = lambd\n",
        "    self.scale_loss = scale_loss\n",
        "  def get_loss(self,loss_type):\n",
        "    if loss_type=='cocoa':\n",
        "      def cocoa_loss(ytrue, ypred):\n",
        "        # temperature = 0.5\n",
        "        # lambd=3.9e-3\n",
        "        # scale_loss=1/32\n",
        "        batch_size, dim_size = ypred.shape[1], ypred.shape[0]\n",
        "        # print(ypred.shape)\n",
        "        # Positive Pairs\n",
        "        pos_error = []\n",
        "        for i in range(batch_size):\n",
        "            sim = tf.linalg.matmul(ypred[:, i, :], ypred[:, i, :], transpose_b=True)\n",
        "            sim = tf.subtract(tf.ones([dim_size, dim_size], dtype=tf.dtypes.float32), sim)\n",
        "            sim = tf.exp(sim/self.temperature)\n",
        "            pos_error.append(tf.reduce_mean(sim))\n",
        "        # Negative pairs\n",
        "        neg_error = 0\n",
        "        for i in range(dim_size):\n",
        "            sim = tf.cast(tf.linalg.matmul(ypred[i], ypred[i], transpose_b=True), dtype=tf.dtypes.float32)\n",
        "            sim = tf.exp(sim /self.temperature)\n",
        "            # sim = tf.add(sim, tf.ones([batch_size, batch_size]))\n",
        "            tri_mask = np.ones(batch_size ** 2, dtype=bool).reshape(batch_size, batch_size)\n",
        "            tri_mask[np.diag_indices(batch_size)] = False\n",
        "            off_diag_sim = tf.reshape(tf.boolean_mask(sim, tri_mask), [batch_size, batch_size - 1])\n",
        "            neg_error += (tf.reduce_mean(off_diag_sim, axis=-1))\n",
        "\n",
        "        error = tf.multiply(tf.reduce_sum(pos_error),self.scale_loss) + self.lambd * tf.reduce_sum(neg_error)\n",
        "\n",
        "        return error\n",
        "      return cocoa_loss\n",
        "# ------------------------------------------------------------------------- #\n",
        "class DotProduct(tf.keras.layers.Layer):\n",
        "    def call(self, x, y):\n",
        "        x = tf.nn.l2_normalize(x, axis=-1)\n",
        "        y = tf.nn.l2_normalize(y, axis=-1)\n",
        "        return tf.linalg.matmul(x, y, transpose_b=True)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------- #\n",
        "class ContrastiveModel(tf.keras.Model):\n",
        "    def __init__(self, embedding_model, loss_fn, temperature=1.0, **kwargs):\n",
        "        super().__init__()\n",
        "        self.embedding_model = embedding_model\n",
        "        self._temperature = temperature\n",
        "        self._similarity_layer = DotProduct()\n",
        "        self._lossfn = loss_fn\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            modality_embeddings = self.embedding_model(data, training=True)\n",
        "\n",
        "            sparse_labels = tf.range(tf.shape(modality_embeddings[0])[0])\n",
        "\n",
        "            pred = modality_embeddings\n",
        "            pred = tf.nn.l2_normalize(tf.stack(pred), axis=-1)\n",
        "\n",
        "            loss = self.compiled_loss(sparse_labels, pred)\n",
        "            loss += sum(self.losses)\n",
        "\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def call(self, input):\n",
        "        return self.embedding_model(input)\n"
      ],
      "id": "cd9bb170"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "e50fd1ba"
      },
      "outputs": [],
      "source": [
        "cocoa_loss = customLoss().get_loss('cocoa')\n",
        "ssl = ContrastiveModel(embedding_model, cocoa_loss)\n",
        "\n",
        "# init_weights = ssl.get_weights()"
      ],
      "id": "e50fd1ba"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60fdda81"
      },
      "source": [
        "## add the base model"
      ],
      "id": "60fdda81"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cb824977"
      },
      "outputs": [],
      "source": [
        "base_model = ssl.embedding_model\n",
        "# for layer in base_model.layers:\n",
        "#     print(layer)\n",
        "#     layer.trainable = False\n",
        "input_x = base_model.input\n",
        "xi = base_model(input_x)\n",
        "x = tf.keras.layers.Concatenate()(xi)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "x = tf.keras.layers.Dense(128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1(0.005))(x)\n",
        "\n",
        "classifier_model = tf.keras.layers.Dense(1,activation=\"sigmoid\",kernel_regularizer=tf.keras.regularizers.L1(0.005),)(x)\n",
        "c_model = tf.keras.Model(input_x, classifier_model)\n",
        "c_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()],\n",
        ")\n",
        "init_weights = c_model.get_weights()"
      ],
      "id": "cb824977"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75552df2",
        "outputId": "3071ca09-1f9a-42aa-81c7-60b99582bad9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 3000, 1)]            0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 30, 1)]              0         []                            \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)        [(None, 39, 30, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " model (Functional)          [(None, 256),                344252    ['input_2[0][0]',             \n",
            "                              (None, 256),                           'input_4[0][0]',             \n",
            "                              (None, 256)]                           'input_6[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 768)                  0         ['model[0][0]',               \n",
            "                                                                     'model[0][1]',               \n",
            "                                                                     'model[0][2]']               \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 768)                  0         ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 128)                  98432     ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 1)                    129       ['dense_9[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 442813 (1.69 MB)\n",
            "Trainable params: 441789 (1.69 MB)\n",
            "Non-trainable params: 1024 (4.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "c_model.summary()"
      ],
      "id": "75552df2"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aPSQrIF5XsjB"
      },
      "outputs": [],
      "source": [
        "complete_list = np.array([\"0995\",\"0999\",\"1000\",\"1006\",\"1008\",\"1010\",\"1014\",\"1016\",\"1018\",\"1020\",\\\n",
        "            \"1022\",\"1024\",\"1026\",\"1028\",\"1037\",\"1039\",\"1041\",\"1043\",\"1045\",\"1057\",\\\n",
        "            \"1059\",\"1069\",\"1071\",\"1073\",\"1082\",\"1084\",\"1086\",\"1088\",\"1089\",\"1093\",\\\n",
        "            \"1095\",\"1097\",\"1104\",\"1106\",\"1108\",\"1110\",\"1112\",\"1116\",\"1118\",\"1120\",\\\n",
        "            \"1122\",\"1127\",\"1129\",\"1131\",\"1135\",\"1137\",\"1139\",\"1143\",\"1145\",\"1147\",\\\n",
        "            \"1151\",\"1153\",\"1155\",\"1157\",\"1161\",\"1163\",\"1169\",\"1171\",\"1172\",\"1174\",\\\n",
        "            \"1176\",\"1178\",\"1182\",\"1186\",\"1191\",\"1193\",\"1195\",\"1197\",\"1198\",\"1200\"])\n",
        "\n"
      ],
      "id": "aPSQrIF5XsjB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4gbFyLvEwR2"
      },
      "outputs": [],
      "source": [
        "final_hist = {}\n",
        "run_data={}\n",
        "for item in ['flow_balance','spo2_balance','noise_balance','apnea_balance','pre_train','downstream',\\\n",
        "             'test_accuracy1','test_precision1','test_recall1','test_fscore1',\\\n",
        "              'test_accuracy2','test_precision2','test_recall2','test_fscore2',\\\n",
        "              'test_accuracy3','test_precision3','test_recall3','test_fscore3']:\n",
        "  run_data[item]=[]\n",
        "\n",
        "for run in range(8):\n",
        "\n",
        "  idx = np.random.randint(len(complete_list), size=len(complete_list))\n",
        "  complete_list=complete_list[idx]\n",
        "  pre_train_list = complete_list[:-10]\n",
        "  downstream_list = complete_list[-10:]\n",
        "  window_size=30\n",
        "  ch1,ch2,ch3_mod,lbls1,lbls2,lbls3,lbls,ch1_down,ch2_down,ch3_down_mod,lbls_down,split_ratio,split_ratio_down,balance=load_data(pre_train_list,downstream_list,window_size)\n",
        "  print(balance)\n",
        "  run_data['pre_train'].append(pre_train_list)\n",
        "  run_data['downstream'].append(downstream_list)\n",
        "\n",
        "  run_data['flow_balance'].append(balance['flow'])\n",
        "  run_data['spo2_balance'].append(balance['spo2'])\n",
        "  run_data['noise_balance'].append(balance['noise'])\n",
        "  run_data['apnea_balance'].append(balance['apnea'])\n",
        "  #Case 1 - full network\n",
        "  print(f\"This is run {run}. Case 1\")\n",
        "  start = time.time()\n",
        "\n",
        "  #pre class train\n",
        "  batch_size=300\n",
        "  train,val=tf.data.Dataset.from_tensor_slices((ch1[0:split_ratio], ch2[0:split_ratio], ch3_mod[0:split_ratio])),\\\n",
        "            tf.data.Dataset.from_tensor_slices((ch1[split_ratio:], ch2[split_ratio:], ch3_mod[split_ratio:]))\n",
        "  train_lbl,val_lbl =  tf.data.Dataset.from_tensor_slices((lbls1[0:split_ratio], lbls2[0:split_ratio], lbls3[0:split_ratio])),\\\n",
        "                      tf.data.Dataset.from_tensor_slices((lbls1[split_ratio:], lbls2[split_ratio:], lbls3[split_ratio:]))\n",
        "  train=tf.data.Dataset.zip(train,train_lbl)\n",
        "  val=tf.data.Dataset.zip(val,val_lbl)\n",
        "  training= train.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  validation = val.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  preclass_hist = preclass_model.fit(training,epochs=50,verbose =0,callbacks=[earlyStopping_class])\n",
        "\n",
        "  # CL\n",
        "  temperature = 0.4\n",
        "  lambd=3.9e-1\n",
        "  scale_loss=1/32\n",
        "  batch_size=8\n",
        "  train=tf.data.Dataset.from_tensor_slices((ch1, ch2, ch3_mod))\n",
        "  X_train= train.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  cocoa_loss = customLoss(temperature,lambd,scale_loss).get_loss('cocoa')\n",
        "  ssl.compile(optimizer='adam', loss=cocoa_loss, metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "  ssl_hist = ssl.fit(X_train, epochs=30,verbose =0,callbacks=[earlyStopping_ssl])\n",
        "\n",
        "  # downstream\n",
        "  batch_size=300\n",
        "  train,val=tf.data.Dataset.from_tensor_slices((ch1_down[0:split_ratio_down], ch2_down[0:split_ratio_down], ch3_down_mod[0:split_ratio_down])),\\\n",
        "            tf.data.Dataset.from_tensor_slices((ch1_down[split_ratio_down:], ch2_down[split_ratio_down:], ch3_down_mod[split_ratio_down:]))\n",
        "  train_lbl,val_lbl =  tf.data.Dataset.from_tensor_slices(lbls_down[0:split_ratio_down]),\\\n",
        "                      tf.data.Dataset.from_tensor_slices(lbls_down[split_ratio_down:])\n",
        "  train=tf.data.Dataset.zip(train,train_lbl)\n",
        "  val=tf.data.Dataset.zip(val,val_lbl)\n",
        "  training= train.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  validation = val.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  class_hist = c_model.fit(training, epochs=80,verbose =0,callbacks=[earlyStopping_class])\n",
        "\n",
        "  test_loss, test_accuracy,test_precision,test_recall = c_model.evaluate(validation)\n",
        "  print(f'Test fscore: {2*test_precision*test_recall/(test_precision+test_recall)}')\n",
        "  run_data['test_accuracy1'].append(test_accuracy)\n",
        "  run_data['test_precision1'].append(test_precision)\n",
        "  run_data['test_recall1'].append(test_recall)\n",
        "  run_data['test_fscore1'].append(2*test_precision*test_recall/(test_precision+test_recall))\n",
        "\n",
        "  final_hist['case1.'+str(run)]=class_hist.history\n",
        "  c_model.set_weights(init_weights)\n",
        "\n",
        "  end = time.time()\n",
        "  print(f'Time took for Case 1: {end - start}s')\n",
        "  ## Case 2 - only CL + downstream ######################\n",
        "  print(f\"This is run {run}. Case 2\")\n",
        "  start = time.time()\n",
        "  # CL\n",
        "  batch_size=8\n",
        "  train=tf.data.Dataset.from_tensor_slices((ch1, ch2, ch3_mod))\n",
        "  X_train= train.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  cocoa_loss = customLoss(temperature,lambd,scale_loss).get_loss('cocoa')\n",
        "  ssl.compile(optimizer='adam', loss=cocoa_loss, metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "  ssl_hist = ssl.fit(X_train, epochs=30,verbose =0,callbacks=[earlyStopping_ssl])\n",
        "\n",
        "  # downstream\n",
        "  batch_size=300\n",
        "  train,val=tf.data.Dataset.from_tensor_slices((ch1_down[0:split_ratio_down], ch2_down[0:split_ratio_down], ch3_down_mod[0:split_ratio_down])),\\\n",
        "            tf.data.Dataset.from_tensor_slices((ch1_down[split_ratio_down:], ch2_down[split_ratio_down:], ch3_down_mod[split_ratio_down:]))\n",
        "  train_lbl,val_lbl =  tf.data.Dataset.from_tensor_slices(lbls_down[0:split_ratio_down]),\\\n",
        "                      tf.data.Dataset.from_tensor_slices(lbls_down[split_ratio_down:])\n",
        "  train=tf.data.Dataset.zip(train,train_lbl)\n",
        "  val=tf.data.Dataset.zip(val,val_lbl)\n",
        "  training= train.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  validation = val.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  class_hist = c_model.fit(training, epochs=80,verbose =0,callbacks=[earlyStopping_class])\n",
        "\n",
        "  test_loss, test_accuracy,test_precision,test_recall = c_model.evaluate(validation)\n",
        "  print(f'Test fscore: {2*test_precision*test_recall/(test_precision+test_recall)}')\n",
        "\n",
        "  run_data['test_accuracy2'].append(test_accuracy)\n",
        "  run_data['test_precision2'].append(test_precision)\n",
        "  run_data['test_recall2'].append(test_recall)\n",
        "  run_data['test_fscore2'].append(2*test_precision*test_recall/(test_precision+test_recall))\n",
        "  final_hist['case2.'+str(run)]=class_hist.history\n",
        "\n",
        "  c_model.set_weights(init_weights)\n",
        "  end = time.time()\n",
        "  print(f'Time took for Case 2: {end - start}s')\n",
        "\n",
        "  ## Case 3 - only downstream #############################\n",
        "  print(f\"This is run {run}. Case 3\")\n",
        "  start = time.time()\n",
        "  # downstream\n",
        "  batch_size=300\n",
        "  train,val=tf.data.Dataset.from_tensor_slices((ch1_down[0:split_ratio_down], ch2_down[0:split_ratio_down], ch3_down_mod[0:split_ratio_down])),\\\n",
        "            tf.data.Dataset.from_tensor_slices((ch1_down[split_ratio_down:], ch2_down[split_ratio_down:], ch3_down_mod[split_ratio_down:]))\n",
        "  train_lbl,val_lbl =  tf.data.Dataset.from_tensor_slices(lbls_down[0:split_ratio_down]),\\\n",
        "                      tf.data.Dataset.from_tensor_slices(lbls_down[split_ratio_down:])\n",
        "  train=tf.data.Dataset.zip(train,train_lbl)\n",
        "  val=tf.data.Dataset.zip(val,val_lbl)\n",
        "  training= train.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  validation = val.batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  class_hist = c_model.fit(training, epochs=80,verbose =0,callbacks=[earlyStopping_class])\n",
        "\n",
        "  test_loss, test_accuracy,test_precision,test_recall = c_model.evaluate(validation)\n",
        "  print(f'Test fscore: {2*test_precision*test_recall/(test_precision+test_recall)}')\n",
        "  run_data['test_accuracy3'].append(test_accuracy)\n",
        "  run_data['test_precision3'].append(test_precision)\n",
        "  run_data['test_recall3'].append(test_recall)\n",
        "  run_data['test_fscore3'].append(2*test_precision*test_recall/(test_precision+test_recall))\n",
        "  final_hist['case3.'+str(run)]=class_hist.history\n",
        "\n",
        "  end = time.time()\n",
        "  print(f'Time took for Case 3: {end - start}s')\n",
        "\n",
        "  c_model.set_weights(init_weights)"
      ],
      "id": "r4gbFyLvEwR2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrADw4MqiErY"
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame(run_data)\n",
        "saved=False\n",
        "num=0\n",
        "while not saved:\n",
        "  try:\n",
        "    saved=True\n",
        "    results.to_csv(rootpath+f'results_{num}.csv', mode='x')\n",
        "  except:\n",
        "    num+=1\n",
        "    saved=False\n",
        "results"
      ],
      "id": "zrADw4MqiErY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju1Ge2IJ5CuO"
      },
      "outputs": [],
      "source": [
        "saved=False\n",
        "train_results = pd.DataFrame(final_hist)\n",
        "num=0\n",
        "while not saved:\n",
        "  try:\n",
        "    saved=True\n",
        "    train_results.to_csv(rootpath+f'train_results_{num}.csv', mode='x')\n",
        "  except:\n",
        "    num+=1\n",
        "    saved=False\n",
        "\n",
        "train_results\n",
        "\n",
        "# import json\n",
        "\n",
        "# with open(rootpath+f'train_results_{num}.txt', 'w') as file:\n",
        "#   file.write(json.dumps(final_hist)) # use `json.loads` to do the reverse"
      ],
      "id": "Ju1Ge2IJ5CuO"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}